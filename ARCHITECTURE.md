# ðŸ—ï¸ Architecture Documentation

## System Architecture Overview

This document provides a comprehensive understanding of the PDF Q&A system architecture for developers new to MCP (Model Context Protocol) and RAG (Retrieval-Augmented Generation).

## ðŸ“Š High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PDF Q&A System                                  â”‚
â”‚                    MCP-Powered Web Application                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    User      â”‚
        â”‚  (Browser)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ HTTP (Port 3000)
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     FRONTEND LAYER                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   React + Vite                 â”‚  â”‚
â”‚  â”‚  â€¢ App.jsx - Chat UI           â”‚  â”‚
â”‚  â”‚  â€¢ ReactMarkdown - Formatting  â”‚  â”‚
â”‚  â”‚  â€¢ jsPDF - Export              â”‚  â”‚
â”‚  â”‚  â€¢ Axios - HTTP Client         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ HTTP REST API
               â”‚ POST /upload
               â”‚ POST /ask/{pdf_id}
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     PROXY LAYER                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   FastAPI HTTP-to-MCP Proxy    â”‚  â”‚
â”‚  â”‚  â€¢ backend/mcp_proxy.py        â”‚  â”‚
â”‚  â”‚  â€¢ MCPClient class             â”‚  â”‚
â”‚  â”‚  â€¢ Subprocess management       â”‚  â”‚
â”‚  â”‚  â€¢ Protocol translation        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ JSON-RPC 2.0 over stdio
               â”‚ (pipes: stdin/stdout)
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MCP SERVER LAYER                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Model Context Protocol       â”‚  â”‚
â”‚  â”‚  â€¢ src/mcp_server.py           â”‚  â”‚
â”‚  â”‚  â€¢ Tools registration          â”‚  â”‚
â”‚  â”‚  â€¢ Resource discovery          â”‚  â”‚
â”‚  â”‚  â€¢ JSON-RPC handling           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     PROCESSING LAYER                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   RAG Pipeline                 â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  1. PDF Processor        â”‚  â”‚  â”‚
â”‚  â”‚  â”‚     â€¢ pdfplumber         â”‚  â”‚  â”‚
â”‚  â”‚  â”‚     â€¢ Text extraction    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚     â€¢ Metadata           â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  2. RAG System           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚     â€¢ Text chunking      â”‚  â”‚  â”‚
â”‚  â”‚  â”‚     â€¢ Embeddings         â”‚  â”‚  â”‚
â”‚  â”‚  â”‚     â€¢ FAISS indexing     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚     â€¢ Similarity search  â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  3. Perplexity Client    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚     â€¢ API calls          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚     â€¢ Answer generation  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚     â€¢ Summarization      â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ”„ Request Flow Diagram

### Complete Request-Response Cycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QUESTION ANSWERING FLOW                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. USER INPUT
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ User types: "What is     â”‚
   â”‚ the main conclusion?"    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
2. FRONTEND (React)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ â€¢ Validate input         â”‚
   â”‚ â€¢ Add to chat UI         â”‚
   â”‚ â€¢ Show typing indicator  â”‚
   â”‚ â€¢ axios.post(/ask)       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ HTTP POST
                â”‚ {question: "What..."}
                â–¼
3. HTTP PROXY (FastAPI)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ â€¢ Receive HTTP request   â”‚
   â”‚ â€¢ Get pdf_path from ID   â”‚
   â”‚ â€¢ Build JSON-RPC msg:    â”‚
   â”‚   {                      â”‚
   â”‚     method: "tools/call" â”‚
   â”‚     params: {            â”‚
   â”‚       name: "answer_q... â”‚
   â”‚       arguments: {...}   â”‚
   â”‚     }                    â”‚
   â”‚   }                      â”‚
   â”‚ â€¢ Write to MCP stdin     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ stdio pipe
                â”‚ JSON-RPC
                â–¼
4. MCP SERVER
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ â€¢ Read from stdin        â”‚
   â”‚ â€¢ Parse JSON-RPC         â”‚
   â”‚ â€¢ Route to tool handler  â”‚
   â”‚ â€¢ call_tool("answer_... â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
5. PDF PROCESSOR
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ â€¢ Load PDF from path     â”‚
   â”‚ â€¢ Extract text           â”‚
   â”‚ â€¢ Split into chunks:     â”‚
   â”‚   ["Chunk 1...",         â”‚
   â”‚    "Chunk 2...",         â”‚
   â”‚    ... 100+ chunks]      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
6. RAG SYSTEM - Embedding
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ â€¢ Load model:            â”‚
   â”‚   all-MiniLM-L6-v2       â”‚
   â”‚ â€¢ Encode chunks:         â”‚
   â”‚   chunk â†’ [0.23, -0.45,  â”‚
   â”‚            ..., 0.12]    â”‚
   â”‚   (384 dimensions)       â”‚
   â”‚ â€¢ Store in FAISS         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
7. RAG SYSTEM - Retrieval
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ â€¢ Embed question         â”‚
   â”‚ â€¢ FAISS similarity:      â”‚
   â”‚   question_vec.search()  â”‚
   â”‚ â€¢ Get top-k=3:           â”‚
   â”‚   indices: [45, 12, 89]  â”‚
   â”‚ â€¢ Retrieve chunks:       â”‚
   â”‚   context = chunks[45] + â”‚
   â”‚             chunks[12] + â”‚
   â”‚             chunks[89]   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
8. PERPLEXITY CLIENT
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ â€¢ Build prompt:          â”‚
   â”‚   "Context: {context}    â”‚
   â”‚    Question: {question}  â”‚
   â”‚    Answer from PDF only" â”‚
   â”‚ â€¢ API call to sonar      â”‚
   â”‚ â€¢ Get raw answer         â”‚
   â”‚ â€¢ Summarize (2nd call):  â”‚
   â”‚   Format as markdown     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
9. RESPONSE PATH
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ MCP Server:              â”‚
   â”‚ â€¢ Wrap in JSON-RPC       â”‚
   â”‚ â€¢ Write to stdout        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ stdio pipe
                â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ HTTP Proxy:              â”‚
   â”‚ â€¢ Read from stdout       â”‚
   â”‚ â€¢ Parse JSON-RPC         â”‚
   â”‚ â€¢ Extract answer text    â”‚
   â”‚ â€¢ Return HTTP response   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ HTTP 200
                â”‚ JSON response
                â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Frontend:                â”‚
   â”‚ â€¢ Receive response       â”‚
   â”‚ â€¢ ReactMarkdown render   â”‚
   â”‚ â€¢ Add to chat history    â”‚
   â”‚ â€¢ Hide typing indicator  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ User sees formatted      â”‚
   â”‚ markdown answer in UI    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total Time: ~1-3 seconds
Token Savings: 98% (compared to sending full PDF)
```

## ðŸ§© Component Details

### 1. Frontend Layer (React)

**Technology Stack:**
- React 18 (UI framework)
- Vite (Build tool & dev server)
- Axios (HTTP client)
- ReactMarkdown (Rendering formatted answers)
- jsPDF (PDF export)

**Key Files:**
```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App.jsx          # Main component
â”‚   â”‚   â”œâ”€â”€ State: chatMessages, currentPdf, loading
â”‚   â”‚   â”œâ”€â”€ Functions: handleUpload, handleAskQuestion
â”‚   â”‚   â””â”€â”€ UI: Chat interface, file upload, export
â”‚   â””â”€â”€ App.css          # Styling
â”‚       â”œâ”€â”€ .chat-message styles
â”‚       â”œâ”€â”€ .markdown-content formatting
â”‚       â””â”€â”€ Responsive design
â””â”€â”€ package.json
```

**State Management:**
```javascript
// Chat message structure
chatMessages = [
  {
    type: 'user',
    content: 'What is the conclusion?',
    timestamp: '2026-01-18T14:30:22'
  },
  {
    type: 'assistant',
    content: '## Conclusion\n\nThe main finding...',
    timestamp: '2026-01-18T14:30:25'
  }
]
```

**API Integration:**
```javascript
// Upload PDF
POST http://localhost:8000/upload
FormData: { file: pdfFile }
Response: { pdf_id, filename, num_pages }

// Ask question
POST http://localhost:8000/ask/{pdf_id}
Body: { question: "..." }
Response: { answers: [{ question, answer, model }] }
```

### 2. Proxy Layer (FastAPI)

**Purpose:** Bridge between web HTTP and MCP stdio protocols

**Key Components:**

```python
class MCPClient:
    """Manages MCP server subprocess communication"""
    
    process: asyncio.subprocess.Process
    request_id: int
    lock: asyncio.Lock  # Prevent concurrent stdin writes
    
    async def start():
        # Spawn: python src/mcp_server.py
        # Capture stdin/stdout/stderr
        
    async def call_tool(name, arguments):
        # 1. Build JSON-RPC request
        # 2. Write to process.stdin
        # 3. Read from process.stdout
        # 4. Parse JSON-RPC response
        # 5. Return result
```

**Lifecycle:**
```
App Startup:
  â””â”€> startup_event()
      â””â”€> mcp_client.start()
          â””â”€> Spawn MCP server process
              â””â”€> Wait 2s for initialization

Request Handling:
  â””â”€> /ask endpoint
      â””â”€> mcp_client.call_tool()
          â””â”€> JSON-RPC request â†’ stdin
          â””â”€> JSON-RPC response â† stdout
          â””â”€> Return HTTP response

App Shutdown:
  â””â”€> shutdown_event()
      â””â”€> mcp_client.stop()
          â””â”€> process.terminate()
```

**Why This Layer Exists:**
- **Protocol Mismatch:** Browsers speak HTTP, MCP speaks stdio
- **Process Management:** MCP server needs to be started/stopped
- **State Translation:** HTTP sessions â†’ MCP tool calls
- **Error Handling:** Convert MCP errors to HTTP status codes

### 3. MCP Server Layer

**MCP Concepts for Beginners:**

**What is MCP?**
Model Context Protocol is a standardized way for AI assistants (like Claude) to interact with external tools and data sources.

**Key MCP Elements:**

1. **Tools** - Functions AI can call
```python
Tool(
    name="answer_question_rag",
    description="Answer questions using RAG",
    inputSchema={
        "pdf_path": "string",
        "question": "string",
        "top_k": "integer (optional)"
    }
)
```

2. **Resources** - Data AI can access
```python
Resource(
    uri="pdf://document.pdf",
    name="document.pdf",
    mimeType="application/pdf"
)
```

3. **JSON-RPC 2.0** - Communication protocol
```json
// Request
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "tools/call",
  "params": {
    "name": "answer_question_rag",
    "arguments": {
      "pdf_path": "doc.pdf",
      "question": "What...?"
    }
  }
}

// Response
{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "content": [
      {
        "type": "text",
        "text": "The answer is..."
      }
    ]
  }
}
```

**Server Implementation:**
```python
from mcp.server import Server
from mcp.server.stdio import stdio_server

app = Server("pdf-qa-server")

@app.list_tools()
async def list_tools():
    """AI asks: What tools are available?"""
    return [tool1, tool2, ...]

@app.call_tool()
async def call_tool(name, arguments):
    """AI says: Call this tool with these args"""
    if name == "answer_question_rag":
        return await handle_rag_query(arguments)

# Start server (stdio communication)
async def main():
    async with stdio_server() as streams:
        await app.run(*streams)
```

### 4. Processing Layer (RAG Pipeline)

**A. PDF Processor**

```python
class PDFProcessor:
    def extract_text(self, pdf_path):
        # pdfplumber opens PDF
        # Extract text page by page
        # Return: "Full document text..."
        
    def extract_metadata(self, pdf_path):
        # Get: title, author, pages, size
        # Return: dict with metadata
```

**B. RAG System**

**What is RAG?**
Retrieval-Augmented Generation improves AI answers by:
1. Finding relevant information (Retrieval)
2. Using it to generate better answers (Augmented Generation)

**Why RAG?**
- **Problem:** AI models have token limits (can't send 1000-page PDF)
- **Solution:** Send only relevant excerpts (3-5 chunks)
- **Benefit:** 98% reduction in tokens + faster responses

**How it Works:**

```python
class OptimizedRAGSystem:
    
    # STEP 1: Index document
    def index_document(self, text, metadata):
        # Split text into chunks
        chunks = split_text(
            text,
            chunk_size=1000,      # chars per chunk
            overlap=200           # overlap for context
        )
        # Example:
        # chunks = [
        #   "Introduction: This paper...",  # 1000 chars
        #   "...novel approach. Methods...", # 1000 chars (200 overlap)
        #   "...experiment. Results show..." # 1000 chars
        # ]
        
        # Generate embeddings (convert text â†’ numbers)
        embeddings = sentence_transformer.encode(chunks)
        # [[0.23, -0.45, ..., 0.12],  # 384 numbers
        #  [0.15, -0.32, ..., 0.08],
        #  ...]
        
        # Store in FAISS (vector database)
        faiss_index.add(embeddings)
        
        # Cache for future queries
        save_to_disk(faiss_index)
    
    # STEP 2: Retrieve relevant chunks
    def get_context_for_question(self, question, top_k=3):
        # Embed question
        q_embedding = model.encode([question])
        # [0.18, -0.39, ..., 0.11]
        
        # Find similar chunks
        distances, indices = faiss_index.search(q_embedding, k=top_k)
        # distances: [0.12, 0.18, 0.25]  # Lower = more similar
        # indices: [45, 12, 89]           # Which chunks
        
        # Get chunk texts
        relevant_chunks = [chunks[i] for i in indices]
        
        # Combine into context
        context = "\n\n".join(relevant_chunks)
        
        return context, metadata_about_chunks
```

**Embeddings Explained:**

```
Text: "The quick brown fox"
       â†“ Sentence Transformer (all-MiniLM-L6-v2)
Vector: [0.23, -0.45, 0.12, ..., 0.89]  (384 numbers)

Why? Similar text â†’ similar vectors
"The quick brown fox" â‰ˆ "A fast brown animal"
[0.23, -0.45, ...]    â‰ˆ [0.25, -0.43, ...]

Different text â†’ different vectors  
"The quick brown fox" â‰  "Python programming"
[0.23, -0.45, ...]    â‰  [-0.78, 0.91, ...]
```

**FAISS Explained:**

```
FAISS = Facebook AI Similarity Search
Purpose: Find nearest vectors super fast

Example:
Index contains 1000 document chunks (1000 vectors)
Question: "What is the methodology?"
Query vector: [0.18, -0.39, ..., 0.11]

FAISS searches all 1000 vectors in milliseconds!
Returns top-3 most similar:
  #45: distance 0.12 (very similar)
  #12: distance 0.18 (similar)
  #89: distance 0.25 (somewhat similar)
```

**C. Perplexity Client**

```python
class PerplexityClient:
    
    def analyze_document(self, question, context):
        """First call: Get answer from PDF content"""
        
        messages = [
            {
                "role": "system",
                "content": "Answer ONLY from provided PDF context"
            },
            {
                "role": "user",
                "content": f"""
                PDF Context:
                {context}
                
                Question: {question}
                """
            }
        ]
        
        response = requests.post(
            "https://api.perplexity.ai/chat/completions",
            json={
                "model": "sonar",
                "messages": messages
            }
        )
        
        raw_answer = response.json()["choices"][0]["message"]["content"]
        return raw_answer
    
    def summarize_answer(self, answer):
        """Second call: Format answer as markdown"""
        
        messages = [
            {
                "role": "user",
                "content": f"""
                Format this answer as structured markdown:
                {answer}
                
                Use headers, bullet points, code blocks.
                """
            }
        ]
        
        formatted = requests.post(...)
        return formatted_answer
```

**Two-Stage Processing:**
1. **Extraction:** Focus on accuracy (answer from PDF)
2. **Summarization:** Focus on formatting (make it pretty)

## ðŸ”Œ Protocol Translation

### HTTP â†” JSON-RPC Mapping

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Protocol Translation                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

HTTP Request:
  POST /ask/doc.pdf_123
  {
    "question": "What is the conclusion?"
  }

        â†“ Proxy translates â†“

JSON-RPC Request (to MCP stdin):
  {
    "jsonrpc": "2.0",
    "id": 1,
    "method": "tools/call",
    "params": {
      "name": "answer_question_rag",
      "arguments": {
        "pdf_path": "/path/to/doc.pdf",
        "question": "What is the conclusion?",
        "top_k": 3
      }
    }
  }

        â†“ MCP processes â†“

JSON-RPC Response (from MCP stdout):
  {
    "jsonrpc": "2.0",
    "id": 1,
    "result": {
      "content": [
        {
          "type": "text",
          "text": "## Conclusion\n\nThe main finding..."
        }
      ]
    }
  }

        â†“ Proxy translates â†“

HTTP Response:
  {
    "pdf_id": "doc.pdf_123",
    "answers": [
      {
        "question": "What is the conclusion?",
        "answer": "## Conclusion\n\nThe main finding...",
        "model": "sonar (via MCP)"
      }
    ],
    "processing_time": 1.23
  }
```

## ðŸ“¦ Data Storage

### In-Memory Storage (Current)

```python
# HTTP Proxy maintains:
pdf_uploads = {
    "doc.pdf_20260118_143000": "/path/to/uploads/doc.pdf",
    "report.pdf_20260118_143100": "/path/to/uploads/report.pdf"
}

# MCP Server maintains:
rag_systems = {
    "/path/to/doc.pdf": RAGSystem(faiss_index, chunks),
    "/path/to/report.pdf": RAGSystem(faiss_index, chunks)
}
```

### Persistent Storage

```
output/
â”œâ”€â”€ uploads/              # Uploaded PDF files
â”‚   â”œâ”€â”€ 20260118_143000_document.pdf
â”‚   â””â”€â”€ 20260118_143100_report.pdf
â”œâ”€â”€ cache/                # FAISS indices (for faster re-indexing)
â”‚   â”œâ”€â”€ document_pdf.faiss
â”‚   â””â”€â”€ report_pdf.faiss
â””â”€â”€ logs/                 # Application logs
    â”œâ”€â”€ backend.log
    â””â”€â”€ mcp_server.log
```

## ðŸ”„ Process Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                System Startup                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. ./start.sh executed
   â”‚
   â”œâ”€> Start MCP Proxy (backend/mcp_proxy.py)
   â”‚   â”‚
   â”‚   â”œâ”€> FastAPI app initializes
   â”‚   â”œâ”€> startup_event() triggered
   â”‚   â”œâ”€> MCPClient.start()
   â”‚   â”‚   â””â”€> Spawn subprocess: python src/mcp_server.py
   â”‚   â”‚       â”œâ”€> MCP server loads models
   â”‚   â”‚       â”œâ”€> Registers tools
   â”‚   â”‚       â””â”€> Listens on stdin
   â”‚   â”‚
   â”‚   â””â”€> Uvicorn starts on port 8000
   â”‚
   â””â”€> Start Frontend (cd frontend && npm run dev)
       â””â”€> Vite dev server on port 3000

2. System ready
   â”œâ”€> Web UI: http://localhost:3000
   â”œâ”€> HTTP API: http://localhost:8000
   â””â”€> MCP: Running as subprocess

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                System Shutdown                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. ./stop.sh executed
   â”‚
   â”œâ”€> Kill processes on ports 8000, 3000
   â”‚
   â”œâ”€> shutdown_event() in proxy
   â”‚   â””â”€> MCPClient.stop()
   â”‚       â””â”€> MCP process terminated
   â”‚
   â””â”€> Cleanup PIDs and temp files
```

## ðŸŽ“ Key Takeaways for Beginners

### What Makes This Architecture Unique?

1. **Pure MCP Backend:**
   - True MCP server (not REST API pretending to be MCP)
   - Can be used by AI assistants directly
   - Standard protocol, not custom

2. **HTTP Bridge Pattern:**
   - Web browsers can't use stdio (MCP's communication method)
   - Proxy solves this by translating protocols
   - Best of both worlds: Web UI + AI integration

3. **RAG Efficiency:**
   - Sending full PDFs to AI is wasteful
   - Vector search finds relevant sections
   - 98% reduction in tokens = faster + cheaper

4. **Two-Stage AI Processing:**
   - First: Accurate extraction from PDF
   - Second: Beautiful formatting
   - Better results than single-pass

### Common Questions

**Q: Why not just use REST API?**
A: REST API works for web only. MCP allows AI assistants (Claude Desktop) to use our tools directly.

**Q: Why subprocess instead of HTTP between proxy and MCP?**
A: MCP protocol uses stdin/stdout. Subprocess is the standard way to communicate with MCP servers.

**Q: Can I skip the proxy and use MCP directly from browser?**
A: No, browsers don't support stdio communication. You need HTTP.

**Q: Why FAISS instead of database?**
A: FAISS is optimized for vector similarity search. Databases are slower for finding "similar" vectors.

**Q: Why local embeddings instead of API?**
A: Sentence Transformers runs locally (no API calls, no costs, no rate limits, privacy preserved).

---

**For more information:**
- [README.md](README.md) - Getting started
- [RAG_COMPARISON.md](RAG_COMPARISON.md) - RAG performance details
- [MCP Documentation](https://modelcontextprotocol.io/) - Official MCP docs
